{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CW6_Vectorizer_J015_24/12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SakshiGehani/J015_NLPassignments/blob/ClassWork/CW6_CountVectorizer_J015_24_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub-Mu6S9AZgk",
        "colab_type": "text"
      },
      "source": [
        "## Sklearn pipeline -- Count Vectorizer, RF/GBM/XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NxgQlTlANA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J8xoD3jA2iC",
        "colab_type": "code",
        "outputId": "496ce47c-88c7-44d5-8fc5-61d538f8b850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "## Twitter dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/zfz/twitter_corpus/master/full-corpus.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>TweetId</th>\n",
              "      <th>TweetDate</th>\n",
              "      <th>TweetText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>apple</td>\n",
              "      <td>positive</td>\n",
              "      <td>126415614616154112</td>\n",
              "      <td>Tue Oct 18 21:53:25 +0000 2011</td>\n",
              "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apple</td>\n",
              "      <td>positive</td>\n",
              "      <td>126404574230740992</td>\n",
              "      <td>Tue Oct 18 21:09:33 +0000 2011</td>\n",
              "      <td>@Apple will be adding more carrier support to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apple</td>\n",
              "      <td>positive</td>\n",
              "      <td>126402758403305474</td>\n",
              "      <td>Tue Oct 18 21:02:20 +0000 2011</td>\n",
              "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apple</td>\n",
              "      <td>positive</td>\n",
              "      <td>126397179614068736</td>\n",
              "      <td>Tue Oct 18 20:40:10 +0000 2011</td>\n",
              "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>apple</td>\n",
              "      <td>positive</td>\n",
              "      <td>126395626979196928</td>\n",
              "      <td>Tue Oct 18 20:34:00 +0000 2011</td>\n",
              "      <td>I just realized that the reason I got into twi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic  ...                                          TweetText\n",
              "0  apple  ...  Now all @Apple has to do is get swype on the i...\n",
              "1  apple  ...  @Apple will be adding more carrier support to ...\n",
              "2  apple  ...  Hilarious @youtube video - guy does a duet wit...\n",
              "3  apple  ...  @RIM you made it too easy for me to switch to ...\n",
              "4  apple  ...  I just realized that the reason I got into twi...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukm5oRbsqHzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing irrelevant sentiments\n",
        "df = df[df['Sentiment']!='irrelevant']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wVdBzXjCc8C",
        "colab_type": "code",
        "outputId": "2e4b411a-9d4a-45dc-e944-624bce4697f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4bG0f7vp4o_",
        "colab_type": "code",
        "outputId": "8b97f8e8-56df-4dfe-c65b-fd4ab124de8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('words')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw3Sgds9p4Hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Preprocessing data\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = set(nltk.corpus.words.words())\n",
        "def preprocess(sen):\n",
        "  sen = sen.lower()\n",
        "  no_punc = sen.translate(sen.maketrans('', '', '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'))\n",
        "  filtered = re.sub(r'(\\s)@\\w+', r'\\1', no_punc)\n",
        "  filtered = re.sub(r'(\\s)#\\w+', r'\\1', filtered)\n",
        "  filtered = filtered.translate(filtered.maketrans('', '', '#@0123456789'))\n",
        "  tokens = word_tokenize(filtered)\n",
        "  no_stop_words = [w for w in tokens if not w in stop_words]     # eliminate stop words\n",
        "  sent = \" \".join(w for w in no_stop_words)\n",
        "  sent = \" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
        "            if w.lower() in words or not w.isalpha())\n",
        "  \n",
        "  return sent\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knulgUgqp4CU",
        "colab_type": "code",
        "outputId": "6cec2d58-bd8a-44f3-b69d-b3e7b711033d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "corpus=df.TweetText.apply(preprocess)\n",
        "print(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                                              get crack\n",
            "1                                  apple carrier support\n",
            "2       hilarious video guy duet pretty much love affair\n",
            "3                            rim made easy switch see ya\n",
            "4                              reason got twitter thanks\n",
            "                              ...                       \n",
            "4537                   modern day autograph like way put\n",
            "4538                                   ways use business\n",
            "4539                          log think bout going sleep\n",
            "4540                                 dumb dont like hush\n",
            "4541           almost bong rip bowl time space continuum\n",
            "Name: TweetText, Length: 3424, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ7C0FepwJnE",
        "colab_type": "code",
        "outputId": "0c855b3f-992b-4f59-de15-af17a8f94315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['abandoned', 'abbas', 'ability', 'able', 'absolutely', 'abstract', 'academy', 'accelerate', 'accelerated', 'acceleration', 'accent', 'acceptable', 'access', 'accidently', 'according', 'account', 'accused', 'acquire', 'acquisition', 'across', 'acting', 'action', 'active', 'activity', 'actual', 'actually', 'ad', 'add', 'added', 'addict', 'addicted', 'additional', 'address', 'administrator', 'admirably', 'admit', 'adobe', 'adopted', 'adoption', 'adult', 'advance', 'advanced', 'advantage', 'advertise', 'advertisement', 'advertising', 'advisor', 'affair', 'afford', 'after', 'afterthought', 'age', 'agency', 'agenda', 'aggressive', 'ago', 'agree', 'agricole', 'ah', 'ahead', 'ai', 'ailing', 'aim', 'aint', 'air', 'airdrop', 'aka', 'ala', 'alamo', 'alarm', 'albatross', 'album', 'alcohol', 'alert', 'algorithm', 'alive', 'allow', 'almost', 'alone', 'along', 'alongside', 'already', 'alright', 'also', 'alternate', 'alternative', 'although', 'alto', 'always', 'amateur', 'amazed', 'amazing', 'amongst', 'amount', 'amused', 'analysis', 'analytics', 'and', 'android', 'angle', 'angry', 'angst', 'announce', 'announcement', 'annoying', 'another', 'answer', 'anti', 'antitrust', 'anyone', 'anything', 'anyway', 'apart', 'apologize', 'apology', 'apparently', 'appeal', 'appear', 'apple', 'application', 'applied', 'apply', 'appointment', 'approach', 'appropriately', 'apt', 'ar', 'arbitrary', 'arc', 'architecture', 'area', 'arent', 'argument', 'around', 'arrival', 'arrive', 'arrogance', 'arrogant', 'art', 'article', 'artisan', 'artist', 'aside', 'ask', 'ass', 'assessment', 'assistant', 'astounding', 'ate', 'attend', 'attention', 'audio', 'august', 'authorization', 'authorize', 'authorized', 'auto', 'autograph', 'automatically', 'autopilot', 'availability', 'available', 'ave', 'avenue', 'average', 'away', 'awesome', 'awesomeness', 'awful', 'awfully', 'awkward', 'ay', 'aye', 'azure', 'ba', 'babe', 'baby', 'back', 'backdrop', 'background', 'backside', 'backup', 'backwards', 'bad', 'badge', 'bag', 'bah', 'baked', 'balance', 'ball', 'ban', 'bangkok', 'banking', 'bar', 'barometer', 'base', 'based', 'basic', 'basically', 'battery', 'batting', 'battle', 'bay', 'beam', 'beaming', 'beat', 'beating', 'beautiful', 'become', 'becoming', 'bed', 'bedtime', 'bee', 'beef', 'bees', 'beg', 'begging', 'begin', 'beginning', 'behind', 'believe', 'belle', 'belong', 'ben', 'beneficial', 'benefit', 'berlin', 'berry', 'best', 'bet', 'beta', 'better', 'beware', 'beyond', 'bidirectional', 'big', 'biggest', 'bill', 'billion', 'bind', 'bing', 'bird', 'birthday', 'bit', 'bitch', 'bite', 'biting', 'biz', 'black', 'blackberry', 'blade', 'blame', 'blank', 'blast', 'blatant', 'blaze', 'blend', 'bless', 'blessed', 'blessing', 'blob', 'block', 'blocked', 'bloody', 'blow', 'blowing', 'blown', 'blue', 'blues', 'boa', 'board', 'bode', 'body', 'bogus', 'bong', 'boo', 'book', 'bookcase', 'booked', 'boost', 'boot', 'booted', 'booth', 'boring', 'boss', 'bother', 'bottom', 'bought', 'bounce', 'bound', 'bouquet', 'bout', 'bowl', 'box', 'boy', 'brain', 'branch', 'brand', 'brat', 'bravo', 'break', 'breakfast', 'breaking', 'brick', 'bridge', 'briefing', 'brightness', 'brilliance', 'brilliant', 'brin', 'bring', 'broadly', 'broke', 'broken', 'brother', 'brought', 'browse', 'browser', 'browsing', 'bruise', 'bu', 'bud', 'buddy', 'buffalo', 'bug', 'buggy', 'build', 'building', 'built', 'bullet', 'bulletin', 'bulletproof', 'bullying', 'bummer', 'bump', 'bunch', 'bunny', 'buried', 'burn', 'bus', 'business', 'busy', 'busyness', 'butler', 'butt', 'button', 'buttons', 'buy', 'buzz', 'by', 'bye', 'cable', 'cake', 'calendar', 'call', 'calling', 'came', 'camera', 'camp', 'campaign', 'camper', 'campus', 'canada', 'cancer', 'canon', 'canso', 'cant', 'cap', 'capability', 'capacity', 'capital', 'capped', 'captain', 'capture', 'car', 'caramba', 'card', 'care', 'careful', 'carrier', 'carry', 'carrying', 'cartoon', 'case', 'cash', 'cast', 'castle', 'cat', 'catastrophe', 'catastrophically', 'catch', 'catchment', 'catchy', 'caught', 'cause', 'celebrity', 'cent', 'center', 'central', 'ceremoniously', 'certain', 'certificate', 'certification', 'certified', 'cerulean', 'cesspit', 'champ', 'chance', 'change', 'changer', 'channel', 'chao', 'chaos', 'charade', 'charge', 'charger', 'charging', 'charity', 'chart', 'chat', 'cheap', 'cheat', 'check', 'checked', 'cheer', 'cheque', 'chest', 'chick', 'chief', 'child', 'china', 'chips', 'choice', 'choose', 'choosy', 'chosen', 'chrome', 'circle', 'city', 'claim', 'class', 'classic', 'classroom', 'clean', 'clear', 'click', 'client', 'clock', 'close', 'closed', 'closely', 'closer', 'closet', 'clothes', 'clothing', 'cloud', 'cloudy', 'club', 'clue', 'coach', 'coast', 'code', 'cofounder', 'coincide', 'coincidence', 'collaboration', 'colleague', 'college', 'color', 'colorful', 'colour', 'combination', 'combine', 'come', 'comes', 'coming', 'comment', 'commodity', 'commons', 'community', 'compact', 'companion', 'company', 'comparison', 'compatibility', 'compatible', 'compelling', 'compete', 'competition', 'competitive', 'competitor', 'compilation', 'compiler', 'complain', 'complete', 'completely', 'complex', 'complicated', 'compo', 'component', 'compose', 'composite', 'computer', 'con', 'concept', 'concerned', 'concrete', 'conductive', 'conference', 'configure', 'confirmed', 'conflict', 'confused', 'connect', 'connected', 'connection', 'connectivity', 'connector', 'consider', 'consideration', 'considered', 'considering', 'console', 'consolidation', 'constrained', 'consulting', 'consumer', 'contact', 'contender', 'content', 'contest', 'continue', 'continued', 'continuous', 'continuously', 'continuum', 'contract', 'contrast', 'control', 'controller', 'conundrum', 'conversation', 'conversion', 'convert', 'converting', 'convince', 'coo', 'cookbook', 'cool', 'cope', 'copied', 'copy', 'cord', 'core', 'corporate', 'corporation', 'correct', 'corrected', 'correction', 'cos', 'cost', 'could', 'count', 'county', 'couple', 'course', 'court', 'courtesy', 'covent', 'coverage', 'covered', 'covering', 'coz', 'crack', 'cracked', 'cracking', 'cranberry', 'cranial', 'crap', 'crash', 'craving', 'crazy', 'cream', 'create', 'creation', 'credential', 'credit', 'creep', 'creepy', 'crew', 'crime', 'crisis', 'critical', 'crome', 'cross', 'crossed', 'crowd', 'crush', 'crushed', 'curate', 'curious', 'current', 'currently', 'curse', 'curve', 'custom', 'customer', 'cut', 'cute', 'cutting', 'cyclone', 'da', 'dad', 'daily', 'dale', 'dam', 'damage', 'damn', 'danger', 'dar', 'dark', 'darkness', 'data', 'date', 'daughter', 'dawn', 'day', 'days', 'de', 'dead', 'deal', 'dealing', 'dear', 'death', 'debate', 'debating', 'debt', 'debut', 'decent', 'decide', 'decision', 'declined', 'default', 'define', 'definitely', 'delay', 'delete', 'delicious', 'delight', 'deliver', 'dell', 'demonstration', 'denounce', 'density', 'dentist', 'department', 'dependent', 'deployment', 'design', 'designed', 'desire', 'desired', 'desk', 'despite', 'destination', 'detailed', 'detection', 'determine', 'dev', 'develop', 'developer', 'development', 'device', 'dick', 'dictation', 'didnt', 'die', 'difference', 'different', 'difficult', 'digging', 'digital', 'digitally', 'dilation', 'dine', 'dinner', 'direct', 'directly', 'director', 'dis', 'disabled', 'disagree', 'disappear', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'disaster', 'disclosed', 'discount', 'discover', 'discuss', 'discussion', 'disguise', 'display', 'dissent', 'distrust', 'ditch', 'doc', 'dock', 'document', 'documentary', 'dodgy', 'doe', 'doesnt', 'dog', 'dogs', 'dollar', 'domain', 'domination', 'donate', 'donated', 'done', 'dont', 'door', 'doorstep', 'dose', 'doubt', 'dough', 'downgrade', 'downtown', 'downward', 'drain', 'dream', 'drew', 'drink', 'drive', 'driver', 'driving', 'drop', 'dropping', 'drying', 'dude', 'due', 'duet', 'duff', 'duly', 'dumb', 'dump', 'duo', 'duplication', 'durable', 'dusting', 'duty', 'dying', 'dynamics', 'ear', 'early', 'earnings', 'earth', 'easier', 'easiest', 'east', 'easter', 'easy', 'eat', 'eating', 'economics', 'edge', 'editor', 'education', 'effect', 'effects', 'efficient', 'efficiently', 'effort', 'eh', 'eight', 'either', 'el', 'electric', 'elegance', 'elevated', 'else', 'em', 'embed', 'embracing', 'emergency', 'emphasis', 'emphasize', 'empire', 'employability', 'employee', 'empty', 'en', 'enable', 'encourage', 'encouraging', 'encrypt', 'encryption', 'end', 'ending', 'endless', 'engage', 'engaged', 'engaging', 'engine', 'engineer', 'enhance', 'enjoy', 'enjoying', 'enlightened', 'enough', 'entering', 'enterprise', 'entertaining', 'entire', 'environment', 'episode', 'equal', 'equipment', 'equivalent', 'eric', 'erika', 'error', 'escape', 'escort', 'especially', 'essential', 'estate', 'eta', 'eu', 'evacuation', 'evangelist', 'even', 'evening', 'event', 'ever', 'every', 'everybody', 'everyday', 'everyone', 'everything', 'everywhere', 'evidence', 'evil', 'evolution', 'ex', 'exact', 'exactly', 'exam', 'example', 'excel', 'excellent', 'except', 'exception', 'exchange', 'excited', 'exciting', 'exclusive', 'excuse', 'executive', 'exercise', 'exhibit', 'expanded', 'expect', 'expensive', 'experience', 'experiment', 'expert', 'explain', 'explaining', 'exploded', 'explorer', 'exposed', 'express', 'extend', 'extended', 'extent', 'extreme', 'ey', 'eye', 'eyelash', 'face', 'facial', 'fact', 'factory', 'fad', 'fade', 'fail', 'failing', 'fair', 'faith', 'fake', 'fall', 'fallen', 'falling', 'false', 'fam', 'family', 'famous', 'fan', 'fancy', 'fantastic', 'fantasy', 'far', 'fast', 'faster', 'fat', 'fault', 'faulty', 'favoring', 'favorite', 'feat', 'feature', 'featured', 'fed', 'federal', 'feed', 'feeding', 'feel', 'feeling', 'fell', 'fellow', 'female', 'fiction', 'fight', 'figure', 'figured', 'file', 'film', 'final', 'finally', 'finance', 'financial', 'find', 'fine', 'finger', 'finish', 'finland', 'first', 'fit', 'five', 'fix', 'fixation', 'fixed', 'fixing', 'flash', 'flat', 'flawless', 'fleet', 'flight', 'flip', 'flirting', 'flood', 'flu', 'focus', 'fold', 'folder', 'follow', 'follower', 'following', 'font', 'foolish', 'football', 'force', 'forced', 'ford', 'forever', 'forget', 'forgetting', 'forgive', 'forgot', 'forgotten', 'form', 'format', 'former', 'forth', 'fortunately', 'forum', 'forward', 'found', 'foundation', 'founder', 'four', 'fox', 'frame', 'framework', 'free', 'freedom', 'freeze', 'freezing', 'fresh', 'fried', 'friend', 'friendliness', 'friendship', 'front', 'frown', 'froze', 'frozen', 'fruit', 'frustration', 'fuel', 'full', 'fully', 'fun', 'function', 'functionality', 'funds', 'funny', 'future', 'futuristic', 'fuzzball', 'gain', 'galaxy', 'gallery', 'game', 'gaming', 'garbage', 'garden', 'garner', 'gate', 'gave', 'gay', 'gear', 'gee', 'geek', 'gem', 'gen', 'generate', 'generation', 'generator', 'genius', 'gentle', 'genuine', 'geo', 'geographic', 'german', 'get', 'getting', 'ghost', 'giant', 'gift', 'gingerbread', 'girl', 'give', 'giveaway', 'giving', 'glad', 'glass', 'global', 'globally', 'globe', 'go', 'god', 'goes', 'going', 'gon', 'gone', 'good', 'goods', 'goodwill', 'goof', 'goose', 'got', 'gotten', 'governance', 'government', 'governor', 'grab', 'grandma', 'graphic', 'grass', 'gratis', 'gray', 'great', 'greater', 'greatly', 'greedy', 'greener', 'grew', 'gross', 'group', 'grown', 'growth', 'guarantee', 'guarded', 'guardian', 'gud', 'guess', 'guide', 'gun', 'guru', 'guy', 'ha', 'hack', 'hacked', 'hacker', 'hah', 'hairline', 'hak', 'half', 'hall', 'hammer', 'hand', 'handle', 'handled', 'handling', 'handy', 'hanging', 'happen', 'happening', 'happier', 'happy', 'hard', 'harder', 'hardware', 'hat', 'hate', 'hater', 'havent', 'hay', 'head', 'headed', 'headline', 'headquarters', 'health', 'healthy', 'hear', 'heart', 'hearts', 'heaven', 'heck', 'hectic', 'hell', 'hello', 'help', 'helpful', 'helping', 'hero', 'hey', 'hi', 'hide', 'high', 'highlight', 'highly', 'hilarious', 'hip', 'hire', 'history', 'hit', 'ho', 'hockey', 'hold', 'holder', 'holding', 'holiday', 'holographic', 'home', 'honest', 'honey', 'honeycomb', 'hong', 'honor', 'hook', 'hooked', 'hookup', 'hope', 'hopeful', 'hopefully', 'horizontal', 'horrible', 'horse', 'hospital', 'host', 'hosting', 'hot', 'hotel', 'hour', 'hourly', 'house', 'household', 'however', 'howl', 'hoy', 'hubby', 'huge', 'huh', 'hulu', 'human', 'humble', 'humor', 'hungry', 'hurry', 'hurt', 'hurting', 'hush', 'hut', 'hybrid', 'hypocritical', 'ice', 'icon', 'id', 'idea', 'identify', 'identity', 'ie', 'ignore', 'ill', 'image', 'imagine', 'imitation', 'immediate', 'imminent', 'immobile', 'impact', 'impersonation', 'implant', 'implement', 'implementation', 'importance', 'important', 'importantly', 'impossible', 'impressive', 'improve', 'improvement', 'inanimate', 'inbuilt', 'incapable', 'incase', 'incentive', 'include', 'included', 'incomparable', 'incompatible', 'inconvenient', 'incorrect', 'increase', 'increasing', 'incredible', 'indeed', 'indexed', 'indicator', 'individual', 'industry', 'inept', 'infamous', 'inferno', 'infinite', 'influential', 'inform', 'information', 'infringement', 'initiative', 'injunction', 'ink', 'inner', 'innovate', 'innovation', 'input', 'insane', 'insanely', 'insert', 'insertion', 'inside', 'insight', 'insist', 'inspiration', 'inspire', 'install', 'installation', 'installer', 'instant', 'instead', 'insurance', 'integrate', 'integration', 'intellectual', 'intelligence', 'intended', 'intent', 'interact', 'interaction', 'interactive', 'interconnect', 'interest', 'interested', 'interesting', 'interface', 'interference', 'internal', 'interrupting', 'interview', 'intriguing', 'introduce', 'introduction', 'invent', 'invention', 'inventor', 'inventory', 'investigate', 'investigating', 'investment', 'invisible', 'involved', 'io', 'iso', 'issue', 'it', 'item', 'iteration', 'jail', 'jane', 'japan', 'jean', 'jet', 'jihad', 'job', 'join', 'joining', 'joint', 'jolly', 'judge', 'juice', 'jump', 'junk', 'justice', 'karaoke', 'karate', 'keep', 'keeping', 'kept', 'key', 'keyboard', 'keynote', 'kick', 'kickoff', 'kill', 'killing', 'kind', 'king', 'kiss', 'kissing', 'kit', 'knew', 'know', 'knowing', 'known', 'kudos', 'la', 'lab', 'lack', 'lag', 'lager', 'laggin', 'laid', 'lame', 'land', 'landing', 'landscape', 'language', 'lapse', 'laser', 'last', 'late', 'later', 'latest', 'latter', 'laugh', 'laughable', 'launch', 'law', 'lawsuit', 'lay', 'laying', 'layout', 'lazy', 'lead', 'leader', 'leadership', 'leading', 'league', 'leak', 'lean', 'leaning', 'leap', 'learn', 'learned', 'learning', 'least', 'leave', 'leaves', 'leaving', 'lecture', 'led', 'left', 'legacy', 'legal', 'leopard', 'less', 'lesson', 'let', 'letdown', 'letter', 'lie', 'lied', 'lien', 'life', 'light', 'lightly', 'like', 'likely', 'liking', 'limit', 'limited', 'limitless', 'line', 'lined', 'link', 'links', 'lion', 'list', 'listed', 'listen', 'listening', 'listing', 'literally', 'little', 'live', 'living', 'lo', 'load', 'loathe', 'lobby', 'local', 'locate', 'location', 'lock', 'locked', 'log', 'logged', 'logging', 'logic', 'login', 'lonely', 'long', 'longer', 'look', 'looking', 'loop', 'loose', 'lord', 'lose', 'losing', 'loss', 'lost', 'lot', 'lots', 'loud', 'love', 'loving', 'low', 'lower', 'loyalty', 'luck', 'lucky', 'lucrative', 'lunch', 'lure', 'mac', 'machine', 'macro', 'mad', 'maddening', 'made', 'madness', 'magazine', 'magical', 'magically', 'mail', 'main', 'mainly', 'maintenance', 'major', 'make', 'making', 'mall', 'man', 'manage', 'management', 'manager', 'mandarin', 'mane', 'mango', 'manhole', 'manipulate', 'manny', 'mansion', 'manually', 'many', 'map', 'mar', 'march', 'marijuana', 'mark', 'market', 'marketeer', 'marketer', 'marketing', 'mary', 'massive', 'master', 'match', 'matter', 'maximize', 'may', 'maybe', 'mean', 'meant', 'measure', 'media', 'meekly', 'meet', 'meeting', 'mein', 'mellon', 'melted', 'member', 'memorial', 'memory', 'men', 'mention', 'mentor', 'menu', 'mercy', 'merge', 'mess', 'message', 'messy', 'met', 'methinks', 'mi', 'middle', 'midnight', 'might', 'mightily', 'mighty', 'migrate', 'mike', 'milky', 'mill', 'million', 'millions', 'mim', 'min', 'mind', 'mine', 'mines', 'minority', 'minus', 'minute', 'misread', 'miss', 'missing', 'mission', 'mistry', 'mix', 'mixer', 'mo', 'mob', 'mobile', 'mode', 'model', 'modern', 'modify', 'mole', 'moment', 'money', 'monitor', 'monopolistic', 'monopoly', 'month', 'monumental', 'mood', 'morning', 'moron', 'morrow', 'mortar', 'mostly', 'mother', 'mourning', 'mouse', 'mouth', 'move', 'movement', 'movie', 'moving', 'much', 'mug', 'multiple', 'music', 'must', 'mute', 'na', 'nam', 'name', 'naming', 'nascent', 'nat', 'national', 'native', 'natural', 'nauseous', 'navigate', 'navigation', 'naw', 'near', 'nearest', 'nearly', 'neat', 'neck', 'need', 'needless', 'needs', 'negative', 'negro', 'nerve', 'nervous', 'net', 'network', 'never', 'new', 'newly', 'news', 'newspaper', 'newsstand', 'next', 'nexus', 'nice', 'nick', 'nigh', 'night', 'nobody', 'non', 'nonanswer', 'none', 'nonstop', 'nope', 'notch', 'note', 'notebook', 'noted', 'nothing', 'notification', 'notified', 'notify', 'novel', 'novelty', 'nowhere', 'nugget', 'number', 'obnoxious', 'obscure', 'obsolete', 'obvious', 'obviously', 'occupy', 'occur', 'odd', 'offer', 'offering', 'office', 'official', 'officially', 'offing', 'often', 'oh', 'old', 'older', 'omission', 'one', 'onto', 'open', 'opening', 'operating', 'opinion', 'opportunity', 'opposite', 'optimization', 'option', 'oracle', 'orbital', 'order', 'ordered', 'organic', 'original', 'os', 'otherwise', 'ouch', 'out', 'outbound', 'outdated', 'outlook', 'outside', 'ova', 'overall', 'overbearing', 'overboard', 'overcapacity', 'overhaul', 'overview', 'owl', 'owner', 'ownership', 'pacific', 'pack', 'page', 'pain', 'painful', 'painfully', 'painless', 'painted', 'pancreatic', 'panel', 'panorama', 'panoramic', 'pants', 'paper', 'para', 'paranormal', 'parker', 'part', 'participation', 'particularly', 'partner', 'partnership', 'party', 'pass', 'passing', 'password', 'past', 'pastel', 'patent', 'pathetic', 'patiently', 'pay', 'paying', 'payment', 'peace', 'pen', 'people', 'per', 'perfect', 'perfectly', 'perform', 'performance', 'perhaps', 'period', 'permission', 'perpetual', 'person', 'personal', 'personalization', 'personally', 'peter', 'petty', 'philosopher', 'philosophy', 'phone', 'photo', 'physical', 'pic', 'pick', 'picked', 'picture', 'piece', 'pile', 'pin', 'pinball', 'pinch', 'ping', 'pink', 'pinto', 'piracy', 'pith', 'place', 'placement', 'plan', 'planet', 'planking', 'plant', 'plate', 'platform', 'play', 'playa', 'playback', 'player', 'playful', 'pleasant', 'please', 'pleasure', 'plot', 'plugged', 'plus', 'pocket', 'point', 'pointing', 'poised', 'policy', 'polish', 'politely', 'poll', 'pondering', 'poop', 'poor', 'poorly', 'pop', 'popular', 'ported', 'portion', 'pose', 'positive', 'possible', 'possibly', 'post', 'posted', 'posting', 'potential', 'pound', 'power', 'powered', 'practical', 'practice', 'pray', 'praying', 'preaching', 'precious', 'predict', 'prefer', 'pregnant', 'premise', 'premium', 'preorder', 'prep', 'present', 'presentation', 'press', 'pretend', 'pretty', 'preview', 'previous', 'price', 'priceless', 'prime', 'principal', 'print', 'printed', 'printer', 'printing', 'privacy', 'private', 'pro', 'probably', 'problem', 'proceeds', 'process', 'processor', 'procrastination', 'prod', 'produce', 'product', 'productivity', 'prof', 'professional', 'profile', 'profit', 'profiting', 'profound', 'program', 'progress', 'progressive', 'project', 'projector', 'promise', 'promising', 'promotion', 'prompt', 'prone', 'proof', 'propaganda', 'proper', 'properly', 'property', 'props', 'protect', 'protection', 'proven', 'provide', 'provided', 'providing', 'proving', 'public', 'publicly', 'puck', 'pull', 'pump', 'pun', 'purchase', 'pure', 'purely', 'purple', 'purpose', 'push', 'pushing', 'puss', 'put', 'python', 'qualify', 'quality', 'quarter', 'quarterly', 'question', 'quick', 'quickly', 'quit', 'quite', 'quote', 'racism', 'racketeering', 'radio', 'rain', 'raise', 'ram', 'ranch', 'randomly', 'range', 'ranked', 'rant', 'rape', 'rapidly', 'rat', 'rate', 'rather', 'raw', 'ray', 'razor', 'reaching', 'reaction', 'read', 'readable', 'reader', 'reading', 'ready', 'real', 'realize', 'really', 'reason', 'reasoning', 'rebuild', 'rebuttal', 'recap', 'receipt', 'receive', 'received', 'recent', 'recently', 'recession', 'reckless', 'recognition', 'recommend', 'record', 'recording', 'recover', 'recruit', 'recruiting', 'red', 'redirection', 'referral', 'regarding', 'regardless', 'regent', 'region', 'register', 'registered', 'registration', 'regular', 'reinstall', 'relate', 'related', 'release', 'relevance', 'relevant', 'reliable', 'relive', 'remain', 'remember', 'remind', 'reminder', 'remote', 'removable', 'remove', 'removing', 'rename', 'render', 'renewal', 'rep', 'repair', 'replace', 'replacement', 'reply', 'report', 'represent', 'reps', 'request', 'require', 'rescue', 'research', 'reseller', 'resemble', 'reservation', 'reserve', 'reshape', 'reside', 'resolution', 'resolve', 'resource', 'respect', 'respond', 'response', 'responsive', 'rest', 'restore', 'restrict', 'restrictive', 'result', 'retail', 'retarded', 'retire', 'retrieve', 'return', 'reunion', 'reveal', 'revealed', 'revenue', 'reverse', 'review', 'revolution', 'revue', 'rewind', 'rice', 'rich', 'rid', 'ridiculously', 'right', 'rim', 'ring', 'ringing', 'rip', 'rise', 'rite', 'rival', 'road', 'roaring', 'robot', 'rock', 'rocking', 'roi', 'role', 'roll', 'rolling', 'rookie', 'room', 'rot', 'rough', 'round', 'roundup', 'row', 'rug', 'rule', 'rumor', 'run', 'running', 'sa', 'sabe', 'sack', 'sad', 'sadly', 'safari', 'safe', 'safety', 'said', 'sake', 'sale', 'salesperson', 'salmonella', 'salute', 'san', 'sandwich', 'save', 'saved', 'saving', 'saw', 'say', 'saying', 'scale', 'schedule', 'school', 'science', 'scientist', 'scrapple', 'scream', 'screen', 'screened', 'screw', 'screwed', 'screwing', 'scribble', 'scroll', 'se', 'seal', 'seamlessly', 'search', 'searching', 'season', 'sec', 'second', 'secret', 'section', 'secure', 'security', 'see', 'seeing', 'seek', 'seeking', 'seem', 'seemingly', 'seen', 'seize', 'select', 'selection', 'self', 'sell', 'selling', 'send', 'sending', 'sense', 'sensible', 'sent', 'sequence', 'series', 'serious', 'seriously', 'server', 'service', 'sesame', 'session', 'set', 'setting', 'settle', 'setup', 'seven', 'several', 'severe', 'sex', 'sexy', 'shagged', 'share', 'sheet', 'shift', 'ship', 'shipping', 'shoot', 'shore', 'short', 'shot', 'shout', 'show', 'shower', 'showing', 'shrewd', 'shuffle', 'shut', 'shutter', 'sick', 'side', 'sigh', 'sign', 'signal', 'silently', 'silicon', 'silly', 'silver', 'similar', 'simple', 'simplicity', 'simply', 'since', 'sincerely', 'sing', 'singing', 'single', 'sinking', 'siris', 'sis', 'sister', 'sit', 'site', 'sith', 'sitting', 'situation', 'six', 'sizes', 'sizing', 'skin', 'skip', 'skittles', 'slacking', 'slash', 'sleek', 'sleep', 'sleeping', 'sleepy', 'slew', 'slick', 'slide', 'slider', 'slightly', 'slinging', 'slipping', 'sloppy', 'slow', 'slowly', 'slows', 'small', 'smart', 'smell', 'smile', 'smooth', 'snatched', 'sneaky', 'snippet', 'snippy', 'snow', 'social', 'socialize', 'soho', 'solar', 'sold', 'solely', 'solution', 'solve', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'son', 'song', 'soon', 'sooner', 'sophistication', 'sorry', 'sort', 'sought', 'soul', 'sound', 'source', 'south', 'southern', 'space', 'spare', 'spat', 'speak', 'speaking', 'spec', 'specialist', 'specs', 'specter', 'speech', 'speed', 'spell', 'spend', 'spending', 'spent', 'spigot', 'spin', 'spinning', 'spiral', 'spoiled', 'spoke', 'spontaneous', 'spontaneously', 'sports', 'spotted', 'spray', 'spring', 'sprint', 'sprung', 'spy', 'squad', 'st', 'stable', 'stack', 'staff', 'staffed', 'stage', 'staged', 'stalking', 'stand', 'standard', 'standing', 'star', 'stare', 'start', 'starting', 'state', 'statement', 'station', 'stay', 'stayed', 'steal', 'step', 'sterling', 'stick', 'stickers', 'sticking', 'sticky', 'still', 'stimulate', 'stink', 'stock', 'stocks', 'stolen', 'stood', 'stop', 'storage', 'store', 'story', 'straight', 'strange', 'stranger', 'strategic', 'strategy', 'stream', 'street', 'streets', 'strongly', 'structure', 'struggling', 'stuck', 'student', 'studio', 'study', 'stuff', 'stupid', 'style', 'stylus', 'subscribe', 'substitute', 'succeed', 'success', 'successful', 'suck', 'sucking', 'sudden', 'suddenly', 'suffering', 'suggest', 'suggesting', 'suing', 'suit', 'suite', 'sum', 'summary', 'summer', 'summit', 'sup', 'super', 'superb', 'superior', 'supplier', 'supply', 'support', 'supporting', 'suppose', 'supreme', 'sure', 'surely', 'surface', 'surfaced', 'surpassing', 'surprising', 'survey', 'survivable', 'surviving', 'swallow', 'sware', 'swear', 'sweet', 'swim', 'swipes', 'switch', 'switched', 'switcher', 'switching', 'symbol', 'sync', 'syntax', 'system', 'ta', 'tab', 'table', 'tablet', 'tag', 'tagged', 'tagger', 'take', 'taken', 'taking', 'talent', 'talk', 'talking', 'tall', 'tango', 'tap', 'tapping', 'target', 'taste', 'taught', 'tax', 'teaching', 'team', 'tear', 'teasing', 'tech', 'technical', 'technological', 'technology', 'techy', 'telegraph', 'tell', 'telling', 'temp', 'template', 'terminal', 'terrible', 'test', 'tested', 'tester', 'testify', 'testing', 'text', 'th', 'tha', 'thank', 'thankful', 'thankfully', 'thanks', 'thats', 'the', 'theater', 'thee', 'theft', 'theme', 'theoretically', 'therapy', 'theres', 'theyre', 'thigh', 'thing', 'think', 'thinking', 'third', 'thirsty', 'tho', 'thoo', 'thorn', 'thorough', 'though', 'thought', 'threat', 'threaten', 'three', 'threw', 'throat', 'throne', 'throw', 'thunderbird', 'thunderbolt', 'thus', 'thyself', 'tick', 'tie', 'tied', 'tiger', 'tighten', 'til', 'till', 'time', 'timed', 'times', 'timing', 'tint', 'tip', 'tipped', 'tired', 'title', 'today', 'together', 'toggle', 'told', 'tomorrow', 'ton', 'tone', 'tonight', 'tonite', 'took', 'tool', 'top', 'topic', 'tossing', 'total', 'totally', 'touch', 'touched', 'touching', 'tough', 'tour', 'towards', 'toy', 'track', 'trade', 'traditional', 'traffic', 'tragic', 'train', 'trainer', 'training', 'transferred', 'transform', 'transition', 'trash', 'treat', 'trial', 'tribute', 'trick', 'tried', 'trip', 'triple', 'trivia', 'tron', 'trouble', 'truck', 'true', 'truly', 'try', 'trying', 'tube', 'tune', 'tuned', 'turn', 'turned', 'turning', 'turns', 'tweet', 'twitter', 'two', 'type', 'ugh', 'ugly', 'ultimate', 'um', 'unable', 'unauthorized', 'unbelievable', 'unborn', 'unconventional', 'undecided', 'undergo', 'underlying', 'understand', 'undo', 'undoubtedly', 'unexpected', 'unfair', 'unfollowing', 'unfortunately', 'unhappy', 'unified', 'unique', 'universe', 'university', 'unknown', 'unladen', 'unless', 'unlike', 'unlock', 'unlocked', 'unlocking', 'unmindful', 'unproductive', 'unquality', 'unreal', 'untill', 'unveil', 'unveiled', 'unveiling', 'unwanted', 'unwrapping', 'upcoming', 'update', 'upgrade', 'uphill', 'upset', 'upstairs', 'ur', 'us', 'usable', 'usage', 'use', 'used', 'useful', 'useless', 'user', 'usual', 'utility', 'utter', 'utterly', 'vagina', 'vain', 'valley', 'valuable', 'variety', 'vat', 'vehicle', 'vendor', 'verge', 'version', 'vertical', 'veteran', 'via', 'vibrate', 'vibrating', 'vicariously', 'victim', 'video', 'vie', 'view', 'village', 'vincent', 'virginity', 'virtual', 'virus', 'visibility', 'vision', 'visit', 'vista', 'visual', 'vital', 'voice', 'volume', 'vote', 'voucher', 'vulnerability', 'wack', 'wad', 'wait', 'waiting', 'wake', 'waking', 'walk', 'wall', 'walled', 'wallet', 'wallpaper', 'wan', 'want', 'wanting', 'war', 'warfare', 'warm', 'warning', 'warranty', 'wash', 'wasnt', 'waste', 'wasted', 'wasting', 'wat', 'watch', 'watchdog', 'watched', 'watching', 'water', 'wave', 'way', 'ways', 'weaken', 'wear', 'weather', 'web', 'week', 'weekend', 'weekly', 'weep', 'weird', 'welcome', 'well', 'wen', 'went', 'werent', 'west', 'weve', 'whale', 'whats', 'wheel', 'whenever', 'whether', 'white', 'whoa', 'whoever', 'whole', 'whoops', 'whore', 'wid', 'wide', 'wife', 'wild', 'win', 'winning', 'wired', 'wireless', 'wise', 'wisely', 'wish', 'wished', 'wishing', 'wit', 'witchcraft', 'within', 'without', 'wo', 'woke', 'woman', 'wonder', 'wonderful', 'wondering', 'wonky', 'wont', 'wooden', 'word', 'work', 'worked', 'working', 'works', 'workshop', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'would', 'wouldnt', 'wounded', 'wow', 'wrestler', 'write', 'writing', 'wrong', 'ya', 'yahoo', 'yapping', 'yea', 'yeah', 'year', 'yearly', 'yellow', 'yeni', 'yeo', 'yep', 'yes', 'yesterday', 'yet', 'yo', 'you', 'youd', 'young', 'youve', 'yr', 'yummy', 'zero', 'zoom']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C91mYsWJzcZa",
        "colab_type": "code",
        "outputId": "7cbb012b-4a99-4a51-c734-62f33057cb88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "print(X.toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG93yVOPZrPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting the count vectorizer array into input dataframe\n",
        "\n",
        "X = pd.DataFrame(X.toarray(), columns=(vectorizer.get_feature_names()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BysOLyHQimT6",
        "colab_type": "code",
        "outputId": "5deb2210-3795-4fb6-d227-c123aa9b8624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "X.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['abandoned', 'abbas', 'ability', 'able', 'absolutely', 'abstract',\n",
              "       'academy', 'accelerate', 'accelerated', 'acceleration',\n",
              "       ...\n",
              "       'yet', 'yo', 'you', 'youd', 'young', 'youve', 'yr', 'yummy', 'zero',\n",
              "       'zoom'],\n",
              "      dtype='object', length=2796)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg_6_5KxkbyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts\n",
        "# splitting into train-test\n",
        "X_train, X_test, y_train, y_test = tts(X, df['Sentiment'], test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niyPGOHFmajC",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LewWrXSlsvrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "params = {'max_depth': [10, 20, 30, None], 'max_features': ['sqrt'], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': range(10,50,10)}\n",
        " \n",
        "gs_rf = GridSearchCV(estimator = rf, param_grid = params, cv = 5, n_jobs = 15, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I7nh-ITsyl3",
        "colab_type": "code",
        "outputId": "42722c9b-4617-45ac-95e7-b38ca5293709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "gs_rf.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
            "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    4.8s\n",
            "[Parallel(n_jobs=15)]: Done 170 tasks      | elapsed:   38.5s\n",
            "[Parallel(n_jobs=15)]: Done 420 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=15)]: Done 720 out of 720 | elapsed:  6.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=15,\n",
              "             param_grid={'max_depth': [10, 20, 30, None],\n",
              "                         'max_features': ['sqrt'],\n",
              "                         'min_samples_leaf': [1, 2, 4],\n",
              "                         'min_samples_split': [2, 5, 10],\n",
              "                         'n_estimators': range(10, 50, 10)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGYTmyxSdb4P",
        "colab_type": "code",
        "outputId": "c015fc40-77fe-4273-c1a6-4f596d16a5f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(gs_rf.predict(X_test),y_test))    # classification report for random forest model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.27      0.65      0.38        82\n",
            "     neutral       0.93      0.74      0.82       858\n",
            "    positive       0.30      0.52      0.38        88\n",
            "\n",
            "    accuracy                           0.71      1028\n",
            "   macro avg       0.50      0.64      0.53      1028\n",
            "weighted avg       0.82      0.71      0.75      1028\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDjME_VsmZH_",
        "colab_type": "text"
      },
      "source": [
        "The extremely high precision and recall values for 'neutral' class show that the model is quite efficient in predicting the 'neutral' tweets. At the same time the unusually low precision values of 'negative' and 'positive' classes show that there is a class imbalance and these classes are not well represented in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZOcoAgffBz8",
        "colab_type": "code",
        "outputId": "af392a7e-afcc-4260-c8a8-c7c1f6c02e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(confusion_matrix(gs_rf.predict(X_test), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 53  23   6]\n",
            " [123 633 102]\n",
            " [ 18  24  46]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpUTpeY2jfT0",
        "colab_type": "code",
        "outputId": "2967eda4-e102-49c8-a523-9461637a1636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "gs_rf.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': None,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 5,\n",
              " 'n_estimators': 20}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT8eLUlcmjUx",
        "colab_type": "text"
      },
      "source": [
        "## ROC Curve and AUC Score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECymQFryj-Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsTpVKNKcH2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_roc_curve(fpr, tpr):\n",
        "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
        "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drKS4StBhkZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs = gs_rf.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZgx5z1Uh3-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs = probs[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F2odzQHjt5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "y_testNew = lb.fit_transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaK5lLl1ltFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_testNew = y_testNew[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gbrJoGSh72h",
        "colab_type": "code",
        "outputId": "8dae34bf-4250-4fee-cac6-21c6acad53d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "auc = roc_auc_score(y_testNew, probs)\n",
        "print('AUC: %.2f' % auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4OFhz65h9oF",
        "colab_type": "code",
        "outputId": "aeea3978-c420-4d6b-a132-7c356074d12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_testNew, probs)\n",
        "plot_roc_curve(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7BD8Uy9nNF_",
        "colab_type": "text"
      },
      "source": [
        "The above ROC curve is for \"negative\" sentiment class. The AUC score is 0.76 or 76%. It means that the Random Forest model predicts the \"negative\" class with a 76% accuracy. Here, the TPR and FPR pertaining to only the \"negative\" class have been taken into account, so we get an approximate measure of how good the model works for the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7_9Yk_HmJf5",
        "colab_type": "text"
      },
      "source": [
        "## Light GBM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze5iUD-2moCQ",
        "colab_type": "code",
        "outputId": "838435c0-10bc-49dd-8c70-801a1fb976f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!pip install lightgbm\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.17.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nZLVMd7nPe_",
        "colab_type": "code",
        "outputId": "745a9f63-1e52-4fae-ab81-c1e52266b2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "params = {\n",
        "    \"objective\" : \"multiclass\",\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'multiclass',\n",
        "    'num_class':3,\n",
        "    'learning_rate':0.01,\n",
        "    'max_depth': 7,\n",
        "    'num_leaves': 127,\n",
        "    'feature_fraction': 0.4,\n",
        "    'bagging_freq': 10,\n",
        "    'num_iterations':1000 ,\n",
        "    'max_bin' : 32}\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()  \n",
        "train = lgb.Dataset(X_train, le.fit_transform(y_train))\n",
        "\n",
        "lgb_model = lgb.train(params, train, 100)\n",
        "\n",
        "pred = lgb_model.predict(X_test)\n",
        "best_pred = [np.argmax(line) for line in pred]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-zGzLEIoL7R",
        "colab_type": "code",
        "outputId": "c3663d3e-58d8-4e4c-86f9-83222012c112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.bincount((le.fit_transform(y_train)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 378, 1653,  365])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btBBeVknoM6T",
        "colab_type": "code",
        "outputId": "71584145-8943-4c6a-ebb4-46013dec269f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "print(classification_report(le.inverse_transform(best_pred),y_test))     # classification report for lgb model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.06      0.50      0.10        22\n",
            "     neutral       0.96      0.68      0.80       968\n",
            "    positive       0.10      0.42      0.17        38\n",
            "\n",
            "    accuracy                           0.66      1028\n",
            "   macro avg       0.38      0.53      0.35      1028\n",
            "weighted avg       0.91      0.66      0.76      1028\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUXsbsawmyma",
        "colab_type": "text"
      },
      "source": [
        "The extremely high precision and recall values for 'neutral' class show that the model is quite efficient in predicting the 'neutral' tweets. At the same time the unusually low precision values of 'negative' and 'positive' classes show that there is a class imbalance and these classes are not well represented in the dataset.\n",
        "\n",
        "Also the accuracy is 66% i.e. less than what we get with the RF model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjvmeVuAlioX",
        "colab_type": "code",
        "outputId": "c02f677a-bc73-4b35-c227-265cfe41ead6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#ROC AUC score\n",
        "#Defining a function that can find the roc auc score for multiple classes\n",
        "def multiclass_roc_auc_score(y_pred, y_test, average='macro'):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred)\n",
        "  return roc_auc_score(y_pred, y_test, average=average)\n",
        "\n",
        "multiclass_roc_auc_score(le.inverse_transform(best_pred), y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6462393489817463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tIFh7mvoQ4M",
        "colab_type": "code",
        "outputId": "60bbed75-d106-4e6a-b689-3aa873d073e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.bincount((best_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 22, 968,  38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jLqtY9RoXRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## defining a function that would find the results at different given thresholds\n",
        "def threshold(arr,thresh):\n",
        "  a = []\n",
        "  for i in range(len(arr)):\n",
        "    if max(arr[i])>thresh:\n",
        "      a.append(np.argmax(arr[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L-CtZ6rdFqZ",
        "colab_type": "code",
        "outputId": "b854cd52-9344-4090-af68-2bc097fc0142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "###for lgbm\n",
        "print(\"\\n 0.6 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(threshold(pred, 0.6)), y_test))\n",
        "print(\"ROC AUC Score = \", multiclass_roc_auc_score(le.inverse_transform(threshold(pred, 0.6)), y_test))\n",
        "print(\"\\n 0.7 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(threshold(pred, 0.7)), y_test))\n",
        "print(\"\\n 0.8 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(threshold(pred, 0.8)), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 0.6 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.01      0.50      0.01         2\n",
            "     neutral       0.88      0.72      0.79       828\n",
            "    positive       0.32      0.25      0.28       198\n",
            "\n",
            "    accuracy                           0.63      1028\n",
            "   macro avg       0.40      0.49      0.36      1028\n",
            "weighted avg       0.77      0.63      0.69      1028\n",
            "\n",
            "ROC AUC Score =  0.6210764325669024\n",
            "\n",
            " 0.7 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00         0\n",
            "     neutral       0.75      0.74      0.75       689\n",
            "    positive       0.50      0.23      0.31       339\n",
            "\n",
            "    accuracy                           0.57      1028\n",
            "   macro avg       0.42      0.32      0.35      1028\n",
            "weighted avg       0.67      0.57      0.60      1028\n",
            "\n",
            "\n",
            " 0.8 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00         0\n",
            "     neutral       0.16      0.75      0.27       149\n",
            "    positive       0.89      0.16      0.27       879\n",
            "\n",
            "    accuracy                           0.24      1028\n",
            "   macro avg       0.35      0.30      0.18      1028\n",
            "weighted avg       0.78      0.24      0.27      1028\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXTKQpt2ng0i",
        "colab_type": "text"
      },
      "source": [
        "Here, we can clearly see that for the LGM model the accuracy goes on decreasing as we increase the threshold -- 66% for 0.5, 63% for 0.6, 57% for 0.7 and finally 24% for 0.8 cut-off. \n",
        "\n",
        "Also the simultaneous decrease in the Recall values for the two classes other than the 'neutral' class clearly shows a class imbalance in the data. These classes are not as well represented in the dataset as the 'neutral' class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyArVN9MeA95",
        "colab_type": "code",
        "outputId": "a7b83410-4202-40c6-c611-7a0328396354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        }
      },
      "source": [
        "###For rf\n",
        "rf_probs = gs_rf.predict_proba(X_test)\n",
        "print(\"\\n Default threshold for rf : \\n\", classification_report(gs_rf.predict(X_test),y_test))\n",
        "print(\"ROC AUC Score = \", multiclass_roc_auc_score(gs_rf.predict(X_test), y_test))\n",
        "print(\"\\n 0.6 threshold for rf : \\n\",classification_report(le.inverse_transform(threshold(rf_probs, 0.6)), y_test))\n",
        "print(\"ROC AUC Score = \", multiclass_roc_auc_score(le.inverse_transform(threshold(rf_probs, 0.6)), y_test))\n",
        "print(\"\\n 0.7 threshold for rf : \\n\",classification_report(le.inverse_transform(threshold(rf_probs, 0.7)), y_test))\n",
        "print(\"\\n 0.8 threshold for rf : \\n\",classification_report(le.inverse_transform(threshold(rf_probs, 0.8)), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Default threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.27      0.65      0.38        82\n",
            "     neutral       0.93      0.74      0.82       858\n",
            "    positive       0.30      0.52      0.38        88\n",
            "\n",
            "    accuracy                           0.71      1028\n",
            "   macro avg       0.50      0.64      0.53      1028\n",
            "weighted avg       0.82      0.71      0.75      1028\n",
            "\n",
            "ROC AUC Score =  0.7277363571424603\n",
            "\n",
            " 0.6 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.14      0.73      0.23        37\n",
            "     neutral       0.81      0.78      0.79       701\n",
            "    positive       0.50      0.27      0.35       290\n",
            "\n",
            "    accuracy                           0.63      1028\n",
            "   macro avg       0.48      0.59      0.46      1028\n",
            "weighted avg       0.70      0.63      0.65      1028\n",
            "\n",
            "ROC AUC Score =  0.6834108206713405\n",
            "\n",
            " 0.7 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.10      0.87      0.18        23\n",
            "     neutral       0.72      0.81      0.76       609\n",
            "    positive       0.56      0.22      0.31       396\n",
            "\n",
            "    accuracy                           0.58      1028\n",
            "   macro avg       0.46      0.63      0.42      1028\n",
            "weighted avg       0.65      0.58      0.58      1028\n",
            "\n",
            "\n",
            " 0.8 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.05      0.91      0.10        11\n",
            "     neutral       0.51      0.84      0.64       412\n",
            "    positive       0.77      0.20      0.31       605\n",
            "\n",
            "    accuracy                           0.46      1028\n",
            "   macro avg       0.44      0.65      0.35      1028\n",
            "weighted avg       0.66      0.46      0.44      1028\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K_Y0svuo4gp",
        "colab_type": "text"
      },
      "source": [
        "Here, we can clearly see that for the RF model the accuracy goes on decreasing as we increase the threshold -- 73%% for 0.5, 63% for 0.6, 57% for 0.7 and finally 47%% for 0.8 cut-off. [The accuracy the RF model gives for thresholds 0.6 and 0.7 is same as the one we get with the LGM model.]\n",
        "\n",
        "\n",
        "Also there is a simultaneous decrease in the Recall value and increase in the \n",
        "Precision value for the 'positive' class and vice versa for the 'negative' class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhb4uLCWnWqZ",
        "colab_type": "text"
      },
      "source": [
        "## XG Boost model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmBTQ25eJ5xc",
        "colab_type": "code",
        "outputId": "cd61935f-3709-42aa-ee0b-c26970ebd30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZYUCNSvlcfS",
        "colab_type": "code",
        "outputId": "70d4f477-62dc-4c54-8e52-dd4f84638d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# fit model no training data\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "xg_pred = xgb.predict(X_test)\n",
        "'''#predictions = [round(value) for value in xg_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#predictions = [round(value) for value in xg_pred]\\n# evaluate predictions\\naccuracy = accuracy_score(y_test, predictions)\\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRdA63KtLn9d",
        "colab_type": "code",
        "outputId": "ef430272-7d49-4b44-b091-91f71cf181e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        }
      },
      "source": [
        "xg_probs = xgb.predict_proba(X_test)\n",
        "print(\"\\n Default threshold for xgb : \\n\", classification_report(xg_pred, y_test))\n",
        "print(\"ROC AUC Score = \", multiclass_roc_auc_score(xg_pred, y_test))\n",
        "print(\"\\n 0.6 threshold for xgb : \\n\",classification_report(le.inverse_transform(threshold(xg_probs, 0.6)), y_test))\n",
        "print(\"ROC AUC Score = \", multiclass_roc_auc_score(le.inverse_transform(threshold(xg_probs, 0.6)), y_test))\n",
        "print(\"\\n 0.7 threshold for xgb : \\n\",classification_report(le.inverse_transform(threshold(xg_probs, 0.7)), y_test))\n",
        "print(\"\\n 0.8 threshold for xgb : \\n\",classification_report(le.inverse_transform(threshold(xg_probs, 0.8)), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Default threshold for xgb : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.12      0.74      0.20        31\n",
            "     neutral       0.99      0.68      0.81       979\n",
            "    positive       0.06      0.56      0.12        18\n",
            "\n",
            "    accuracy                           0.68      1028\n",
            "   macro avg       0.39      0.66      0.38      1028\n",
            "weighted avg       0.94      0.68      0.78      1028\n",
            "\n",
            "ROC AUC Score =  0.7439487356140235\n",
            "\n",
            " 0.6 threshold for xgb : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.06      0.79      0.11        14\n",
            "     neutral       0.96      0.72      0.82       902\n",
            "    positive       0.25      0.34      0.29       112\n",
            "\n",
            "    accuracy                           0.68      1028\n",
            "   macro avg       0.42      0.62      0.40      1028\n",
            "weighted avg       0.87      0.68      0.75      1028\n",
            "\n",
            "ROC AUC Score =  0.7167357795184343\n",
            "\n",
            " 0.7 threshold for xgb : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.04      0.88      0.07         8\n",
            "     neutral       0.81      0.76      0.78       718\n",
            "    positive       0.45      0.23      0.30       302\n",
            "\n",
            "    accuracy                           0.61      1028\n",
            "   macro avg       0.43      0.62      0.39      1028\n",
            "weighted avg       0.69      0.61      0.64      1028\n",
            "\n",
            "\n",
            " 0.8 threshold for xgb : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.01      1.00      0.02         2\n",
            "     neutral       0.03      0.86      0.05        22\n",
            "    positive       0.99      0.15      0.26      1004\n",
            "\n",
            "    accuracy                           0.17      1028\n",
            "   macro avg       0.34      0.67      0.11      1028\n",
            "weighted avg       0.97      0.17      0.26      1028\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrCxWenuo6wY",
        "colab_type": "text"
      },
      "source": [
        "Here, we can clearly see that for the XGBoost model the accuracy goes on decreasing as we increase the threshold -- 68%% for 0.5, 68% for 0.6, 61% for 0.7 and finally 17%% for 0.8 cut-off. Thus we see that it decreases quite slowly initially till 0.7 cut-off and then suddenly comes down to 17% at 80% cut-off.\n",
        "\n",
        "\n",
        "Also there is a simultaneous increase in the Recall value and decrease in the \n",
        "Precision value for the 'negative' class and vice versa for the other two classes. \n",
        "\n",
        "The extremely high precision value of 0.99 for 'positive' class when keeping the cut-off at 0.8, clearly shows a case of over-fitting in the train data that leads to a reduced accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUVhuS4xNmVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}