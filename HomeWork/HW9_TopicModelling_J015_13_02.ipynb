{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW9_TopicModelling_J015_13/02.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNXYwZe60+UlO7/ah3CgDY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SakshiGehani/J015_NLPassignments/blob/HomeWork/HW9_TopicModelling_J015_13_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qElkVeamlkH4",
        "colab_type": "text"
      },
      "source": [
        "## Topic Modelling using nmf and lda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JoqTdNuldNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyfzNjrelp_P",
        "colab_type": "code",
        "outputId": "6664abd4-cc6d-4b83-c116-22a1d32d0b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klb9cEehmGLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/My Drive/.kaggle/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDCW9nIwmI_c",
        "colab_type": "code",
        "outputId": "8b08bd7e-5a59-42ca-a765-ccafe0ca39ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "!kaggle datasets download -d hj5992/nlp-topic-modelling"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading nlp-topic-modelling.zip to /content\n",
            " 98% 112M/115M [00:01<00:00, 61.4MB/s]\n",
            "100% 115M/115M [00:01<00:00, 71.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sflhFDsAmdYL",
        "colab_type": "code",
        "outputId": "59703cdc-4291-450d-9dbb-0dde44fe052c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip nlp-topic-modelling.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  nlp-topic-modelling.zip\n",
            "  inflating: Reviews.csv             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qodXaWXdmi5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "9bdf908b-804d-4137-df8f-4dd0074062c3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"Reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOQZeryHmofk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np;\n",
        "import scipy as sp;\n",
        "import sklearn;\n",
        "import sys;\n",
        "from nltk.corpus import stopwords;\n",
        "import nltk;\n",
        "from gensim.models import ldamodel\n",
        "import gensim.corpora;\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer;\n",
        "from sklearn.decomposition import NMF;\n",
        "from sklearn.preprocessing import normalize;\n",
        "import pickle;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrVzuit8mzPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.iloc[:2000,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoM2qS2xnhwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0d6fc377-6ac7-4f2e-db3c-2281f8985162"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGi8V4o3nj2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "f8958e4c-2230-4e8a-81aa-09692b9bf6c1"
      },
      "source": [
        "text = df.Summary\n",
        "text"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                Good Quality Dog Food\n",
              "1                    Not as Advertised\n",
              "2                \"Delight\" says it all\n",
              "3                       Cough Medicine\n",
              "4                          Great taffy\n",
              "                     ...              \n",
              "1995    Great Waffles for us non-cooks\n",
              "1996    Excellent Fluffy Pancakes.....\n",
              "1997                    Good Basic Mix\n",
              "1998       Good pancakes, lots of work\n",
              "1999            waffles, schmaffles !!\n",
              "Name: Summary, Length: 2000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWs2xE0LrFoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "cb7f335a-8398-43a9-caca-7b0e265e576a"
      },
      "source": [
        "# importing required modules\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJyZkCpIvtps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def lemma(pos):\n",
        "  lem = WordNetLemmatizer()\n",
        "  lemma = []\n",
        "  for word in pos:\n",
        "    for w in word:\n",
        "      pos_value = \"\"\n",
        "      if (w[1].startswith('J')):\n",
        "        pos_value = wordnet.ADJ\n",
        "      elif (w[1].startswith('V')):\n",
        "        pos_value = wordnet.VERB\n",
        "      elif (w[1].startswith('N')):\n",
        "        pos_value = wordnet.NOUN\n",
        "      elif (w[1].startswith('R')):\n",
        "        pos_value = wordnet.ADV \n",
        "      else:\n",
        "        continue\n",
        "      lemma.append(lem.lemmatize(w[0],pos_value))\n",
        "  return (lemma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxp2dLIPntwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Preprocessing data\n",
        "\n",
        "stop_words = set(stopwords.words('english'))      # for unique entries -> set()\n",
        "#stop_words.add(\"nan\")\n",
        "words = set(nltk.corpus.words.words())\n",
        "def preprocess(sen):\n",
        "  sen = sen.lower()\n",
        "  no_punc = sen.translate(sen.maketrans('', '', '!\"$%&\\'()#@*+,-./:;<=>?[\\\\]^_`{|}~'))      ## removing all punctuation marks\n",
        "  filtered = no_punc.translate(no_punc.maketrans('', '', '#@0123456789'))           ## removing digits\n",
        "  tokens = word_tokenize(filtered)                        ## creating a list of tokens\n",
        "  no_stop_words = [w for w in tokens if not w in stop_words]     # eliminate stop words;  returns list of lists\n",
        "  \n",
        "  pos = []\n",
        "  pos.append(nltk.pos_tag(no_stop_words))\n",
        "  lemmatized = lemma(pos)\n",
        "  sent = \" \".join(w for w in lemmatized)\n",
        "  \n",
        "  return sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TxdSeSXdzYgF",
        "colab": {}
      },
      "source": [
        "df[\"clean_text\"] = text.apply(preprocess)\n",
        "clean_text = df.clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DbWnXDs1QXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "d4e2083d-8863-46df-e5ff-c70873092c4d"
      },
      "source": [
        "df.clean_text "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          good quality dog food\n",
              "1                     advertised\n",
              "2                    delight say\n",
              "3                 cough medicine\n",
              "4                    great taffy\n",
              "                  ...           \n",
              "1995       great waffle noncooks\n",
              "1996    excellent fluffy pancake\n",
              "1997              good basic mix\n",
              "1998       good pancake lot work\n",
              "1999           waffle schmaffles\n",
              "Name: clean_text, Length: 2000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DD4Le4C4myb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "931d8279-851f-401c-ed69-02b0620c0323"
      },
      "source": [
        "clean_text"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          good quality dog food\n",
              "1                     advertised\n",
              "2                    delight say\n",
              "3                 cough medicine\n",
              "4                    great taffy\n",
              "                  ...           \n",
              "1995       great waffle noncooks\n",
              "1996    excellent fluffy pancake\n",
              "1997              good basic mix\n",
              "1998       good pancake lot work\n",
              "1999           waffle schmaffles\n",
              "Name: clean_text, Length: 2000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3qRFAWX4qZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = [d.split() for d in df.clean_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuybJ_E6oMEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the number of Topics we need to cluster\n",
        "num_topics = 10\n",
        "\n",
        "# First, we obtain a id-2-word dictionary. For each headline, we will use the dictionary to obtain a mapping of the word id to their word counts.\n",
        "id2word = gensim.corpora.Dictionary(dataset);\n",
        "corpus = [id2word.doc2bow(txt) for txt in dataset];\n",
        "lda = ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn-GWvYsq9lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generating LDA topics\n",
        "def get_lda_topics(model, num_topics):\n",
        "    word_dict = {};\n",
        "    for i in range(num_topics):\n",
        "        words = model.show_topic(i, topn = 20);\n",
        "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words];\n",
        "    return pd.DataFrame(word_dict);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyEUBZAhtpbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "dc02ea45-525e-4418-e5cb-43d3a87ecf15"
      },
      "source": [
        "get_lda_topics(lda, num_topics)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic # 01</th>\n",
              "      <th>Topic # 02</th>\n",
              "      <th>Topic # 03</th>\n",
              "      <th>Topic # 04</th>\n",
              "      <th>Topic # 05</th>\n",
              "      <th>Topic # 06</th>\n",
              "      <th>Topic # 07</th>\n",
              "      <th>Topic # 08</th>\n",
              "      <th>Topic # 09</th>\n",
              "      <th>Topic # 10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good</td>\n",
              "      <td>tea</td>\n",
              "      <td>great</td>\n",
              "      <td>great</td>\n",
              "      <td>love</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>chip</td>\n",
              "      <td>good</td>\n",
              "      <td>tasty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love</td>\n",
              "      <td>best</td>\n",
              "      <td>chip</td>\n",
              "      <td>best</td>\n",
              "      <td>yum</td>\n",
              "      <td>delicious</td>\n",
              "      <td>pop</td>\n",
              "      <td>pop</td>\n",
              "      <td>chip</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>great</td>\n",
              "      <td>delicious</td>\n",
              "      <td>best</td>\n",
              "      <td>love</td>\n",
              "      <td>taste</td>\n",
              "      <td>best</td>\n",
              "      <td>chip</td>\n",
              "      <td>love</td>\n",
              "      <td>great</td>\n",
              "      <td>great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>taste</td>\n",
              "      <td>ever</td>\n",
              "      <td>taste</td>\n",
              "      <td>favorite</td>\n",
              "      <td>yummy</td>\n",
              "      <td>chip</td>\n",
              "      <td>best</td>\n",
              "      <td>best</td>\n",
              "      <td>love</td>\n",
              "      <td>awesome</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>product</td>\n",
              "      <td>great</td>\n",
              "      <td>dog</td>\n",
              "      <td>popchips</td>\n",
              "      <td>chip</td>\n",
              "      <td>flavor</td>\n",
              "      <td>love</td>\n",
              "      <td>cat</td>\n",
              "      <td>well</td>\n",
              "      <td>chip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dog</td>\n",
              "      <td>food</td>\n",
              "      <td>snack</td>\n",
              "      <td>taste</td>\n",
              "      <td>best</td>\n",
              "      <td>ever</td>\n",
              "      <td>hard</td>\n",
              "      <td>excellent</td>\n",
              "      <td>taste</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>food</td>\n",
              "      <td>yummy</td>\n",
              "      <td>tea</td>\n",
              "      <td>product</td>\n",
              "      <td>tea</td>\n",
              "      <td>taste</td>\n",
              "      <td>taste</td>\n",
              "      <td>awful</td>\n",
              "      <td>delicious</td>\n",
              "      <td>excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>chip</td>\n",
              "      <td>good</td>\n",
              "      <td>love</td>\n",
              "      <td>hot</td>\n",
              "      <td>product</td>\n",
              "      <td>salt</td>\n",
              "      <td>delicious</td>\n",
              "      <td>yum</td>\n",
              "      <td>product</td>\n",
              "      <td>quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>flavor</td>\n",
              "      <td>product</td>\n",
              "      <td>potato</td>\n",
              "      <td>chip</td>\n",
              "      <td>ever</td>\n",
              "      <td>coffee</td>\n",
              "      <td>tasty</td>\n",
              "      <td>snack</td>\n",
              "      <td>healthy</td>\n",
              "      <td>favorite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>cute</td>\n",
              "      <td>chip</td>\n",
              "      <td>good</td>\n",
              "      <td>tasty</td>\n",
              "      <td>great</td>\n",
              "      <td>food</td>\n",
              "      <td>price</td>\n",
              "      <td>perfect</td>\n",
              "      <td>stuff</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>easy</td>\n",
              "      <td>salt</td>\n",
              "      <td>mix</td>\n",
              "      <td>food</td>\n",
              "      <td>flavor</td>\n",
              "      <td>nice</td>\n",
              "      <td>really</td>\n",
              "      <td>coffee</td>\n",
              "      <td>best</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bad</td>\n",
              "      <td>price</td>\n",
              "      <td>kettle</td>\n",
              "      <td>sauce</td>\n",
              "      <td>well</td>\n",
              "      <td>bite</td>\n",
              "      <td>stuff</td>\n",
              "      <td>great</td>\n",
              "      <td>find</td>\n",
              "      <td>flavor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>cat</td>\n",
              "      <td>taste</td>\n",
              "      <td>deal</td>\n",
              "      <td>price</td>\n",
              "      <td>coffee</td>\n",
              "      <td>great</td>\n",
              "      <td>excellent</td>\n",
              "      <td>amaze</td>\n",
              "      <td>price</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>fresh</td>\n",
              "      <td>excellent</td>\n",
              "      <td>salty</td>\n",
              "      <td>snack</td>\n",
              "      <td>salt</td>\n",
              "      <td>love</td>\n",
              "      <td>rule</td>\n",
              "      <td>delicious</td>\n",
              "      <td>much</td>\n",
              "      <td>taste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>coffee</td>\n",
              "      <td>omg</td>\n",
              "      <td>flavor</td>\n",
              "      <td>oatmeal</td>\n",
              "      <td>wonderful</td>\n",
              "      <td>excellent</td>\n",
              "      <td>work</td>\n",
              "      <td>favorite</td>\n",
              "      <td>hot</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>day</td>\n",
              "      <td>popchips</td>\n",
              "      <td>food</td>\n",
              "      <td>candy</td>\n",
              "      <td>healthy</td>\n",
              "      <td>pack</td>\n",
              "      <td>great</td>\n",
              "      <td>go</td>\n",
              "      <td>buy</td>\n",
              "      <td>delicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>nice</td>\n",
              "      <td>baby</td>\n",
              "      <td>sweet</td>\n",
              "      <td>tea</td>\n",
              "      <td>look</td>\n",
              "      <td>different</td>\n",
              "      <td>food</td>\n",
              "      <td>popchips</td>\n",
              "      <td>way</td>\n",
              "      <td>ever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>dont</td>\n",
              "      <td>low</td>\n",
              "      <td>awesome</td>\n",
              "      <td>money</td>\n",
              "      <td>energy</td>\n",
              "      <td>fruit</td>\n",
              "      <td>flavor</td>\n",
              "      <td>food</td>\n",
              "      <td>hard</td>\n",
              "      <td>cereal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>delicious</td>\n",
              "      <td>chocolate</td>\n",
              "      <td>make</td>\n",
              "      <td>perfect</td>\n",
              "      <td>fantastic</td>\n",
              "      <td>ive</td>\n",
              "      <td>dog</td>\n",
              "      <td>ever</td>\n",
              "      <td>pop</td>\n",
              "      <td>sugar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>bag</td>\n",
              "      <td>get</td>\n",
              "      <td>little</td>\n",
              "      <td>make</td>\n",
              "      <td>vinegar</td>\n",
              "      <td>eat</td>\n",
              "      <td>perfect</td>\n",
              "      <td>flavor</td>\n",
              "      <td>pretty</td>\n",
              "      <td>make</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic # 01 Topic # 02 Topic # 03  ... Topic # 08 Topic # 09 Topic # 10\n",
              "0        good        tea      great  ...       chip       good      tasty\n",
              "1        love       best       chip  ...        pop       chip       good\n",
              "2       great  delicious       best  ...       love      great      great\n",
              "3       taste       ever      taste  ...       best       love    awesome\n",
              "4     product      great        dog  ...        cat       well       chip\n",
              "5         dog       food      snack  ...  excellent      taste       best\n",
              "6        food      yummy        tea  ...      awful  delicious  excellent\n",
              "7        chip       good       love  ...        yum    product    quality\n",
              "8      flavor    product     potato  ...      snack    healthy   favorite\n",
              "9        cute       chip       good  ...    perfect      stuff       food\n",
              "10       easy       salt        mix  ...     coffee       best        dog\n",
              "11        bad      price     kettle  ...      great       find     flavor\n",
              "12        cat      taste       deal  ...      amaze      price    healthy\n",
              "13      fresh  excellent      salty  ...  delicious       much      taste\n",
              "14     coffee        omg     flavor  ...   favorite        hot        bad\n",
              "15        day   popchips       food  ...         go        buy  delicious\n",
              "16       nice       baby      sweet  ...   popchips        way       ever\n",
              "17       dont        low    awesome  ...       food       hard     cereal\n",
              "18  delicious  chocolate       make  ...       ever        pop      sugar\n",
              "19        bag        get     little  ...     flavor     pretty       make\n",
              "\n",
              "[20 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1mrc7XXTOBK",
        "colab_type": "text"
      },
      "source": [
        "#***using NMF to get topics*** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyhJ529wxuAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "38f27921-d39f-4d7f-9832-751d3216987a"
      },
      "source": [
        "clean_text"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          good quality dog food\n",
              "1                     advertised\n",
              "2                    delight say\n",
              "3                 cough medicine\n",
              "4                    great taffy\n",
              "                  ...           \n",
              "1995       great waffle noncooks\n",
              "1996    excellent fluffy pancake\n",
              "1997              good basic mix\n",
              "1998       good pancake lot work\n",
              "1999           waffle schmaffles\n",
              "Name: clean_text, Length: 2000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHxAcP8XRLpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To reduce the size of the matrix, to speed up computation, we will set the maximum feature size to 5000, which will take the top 5000 best features that can contribute to our model.\n",
        "vectorizer = CountVectorizer(analyzer='word', max_features=5000);\n",
        "X_counts = vectorizer.fit_transform(clean_text);\n",
        "#Next, we set a TfIdf Transformer, and transform the counts with the model.\n",
        "transformer = TfidfTransformer(smooth_idf=False);\n",
        "X_tfidf = transformer.fit_transform(X_counts);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am2HJlygRM8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#And now we normalize the TfIdf values to unit length for each row.\n",
        "X_tfidf_norm = normalize(X_tfidf, norm='l1', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92_TdzSLSbqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "b3cab447-4ed6-4568-940f-89ce22d7ca5a"
      },
      "source": [
        "#And finally, obtain a NMF model, and fit it with the sentences.\n",
        "\n",
        "#obtain a NMF model.\n",
        "model = NMF(n_components=num_topics, init='nndsvd');\n",
        "#fit the model\n",
        "model.fit(X_tfidf_norm)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NMF(alpha=0.0, beta_loss='frobenius', init='nndsvd', l1_ratio=0.0, max_iter=200,\n",
              "    n_components=10, random_state=None, shuffle=False, solver='cd', tol=0.0001,\n",
              "    verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qugqN5ziSkoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generating NMF topics:\n",
        "\n",
        "def get_nmf_topics(model, n_top_words):\n",
        "    \n",
        "    #the word ids obtained need to be reverse-mapped to the words so we can print the topic names.\n",
        "    feat_names = vectorizer.get_feature_names()\n",
        "    \n",
        "    word_dict = {};\n",
        "    for i in range(num_topics):\n",
        "        \n",
        "        #for each topic, obtain the largest values, and add the words they map to into the dictionary.\n",
        "        words_ids = model.components_[i].argsort()[:-20 - 1:-1]\n",
        "        words = [feat_names[key] for key in words_ids]\n",
        "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = words;\n",
        "    \n",
        "    return pd.DataFrame(word_dict);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIyp7zP3S5kU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "8ef8e714-dc88-4cf7-b596-3d0145b8c768"
      },
      "source": [
        "get_nmf_topics(model, 20)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic # 01</th>\n",
              "      <th>Topic # 02</th>\n",
              "      <th>Topic # 03</th>\n",
              "      <th>Topic # 04</th>\n",
              "      <th>Topic # 05</th>\n",
              "      <th>Topic # 06</th>\n",
              "      <th>Topic # 07</th>\n",
              "      <th>Topic # 08</th>\n",
              "      <th>Topic # 09</th>\n",
              "      <th>Topic # 10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good</td>\n",
              "      <td>delicious</td>\n",
              "      <td>love</td>\n",
              "      <td>great</td>\n",
              "      <td>best</td>\n",
              "      <td>yum</td>\n",
              "      <td>yummy</td>\n",
              "      <td>chip</td>\n",
              "      <td>tasty</td>\n",
              "      <td>popchips</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>taste</td>\n",
              "      <td>absolutely</td>\n",
              "      <td>dog</td>\n",
              "      <td>product</td>\n",
              "      <td>ever</td>\n",
              "      <td>pop</td>\n",
              "      <td>tummy</td>\n",
              "      <td>pop</td>\n",
              "      <td>easy</td>\n",
              "      <td>variety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>flavor</td>\n",
              "      <td>healthy</td>\n",
              "      <td>cat</td>\n",
              "      <td>taste</td>\n",
              "      <td>tea</td>\n",
              "      <td>healthy</td>\n",
              "      <td>treat</td>\n",
              "      <td>excellent</td>\n",
              "      <td>organic</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stuff</td>\n",
              "      <td>tea</td>\n",
              "      <td>stuff</td>\n",
              "      <td>snack</td>\n",
              "      <td>stevia</td>\n",
              "      <td>say</td>\n",
              "      <td>small</td>\n",
              "      <td>kettle</td>\n",
              "      <td>crunchy</td>\n",
              "      <td>rule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>product</td>\n",
              "      <td>easy</td>\n",
              "      <td>food</td>\n",
              "      <td>food</td>\n",
              "      <td>sauce</td>\n",
              "      <td>falafel</td>\n",
              "      <td>different</td>\n",
              "      <td>favorite</td>\n",
              "      <td>healthy</td>\n",
              "      <td>luuuv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pretty</td>\n",
              "      <td>awesome</td>\n",
              "      <td>product</td>\n",
              "      <td>deal</td>\n",
              "      <td>coffee</td>\n",
              "      <td>want</td>\n",
              "      <td>oooh</td>\n",
              "      <td>awesome</td>\n",
              "      <td>salty</td>\n",
              "      <td>weightwatchers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>coffee</td>\n",
              "      <td>product</td>\n",
              "      <td>snack</td>\n",
              "      <td>price</td>\n",
              "      <td>ive</td>\n",
              "      <td>something</td>\n",
              "      <td>yummies</td>\n",
              "      <td>potato</td>\n",
              "      <td>fresh</td>\n",
              "      <td>flavor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>food</td>\n",
              "      <td>hot</td>\n",
              "      <td>son</td>\n",
              "      <td>stuff</td>\n",
              "      <td>flavor</td>\n",
              "      <td>snack</td>\n",
              "      <td>snack</td>\n",
              "      <td>ever</td>\n",
              "      <td>fruit</td>\n",
              "      <td>favorite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>healthy</td>\n",
              "      <td>pretty</td>\n",
              "      <td>mueslix</td>\n",
              "      <td>dog</td>\n",
              "      <td>simply</td>\n",
              "      <td>really</td>\n",
              "      <td>potato</td>\n",
              "      <td>salt</td>\n",
              "      <td>beware</td>\n",
              "      <td>hella</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>really</td>\n",
              "      <td>omg</td>\n",
              "      <td>family</td>\n",
              "      <td>value</td>\n",
              "      <td>food</td>\n",
              "      <td>sweetener</td>\n",
              "      <td>healthy</td>\n",
              "      <td>addictive</td>\n",
              "      <td>sooo</td>\n",
              "      <td>wonderfully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>price</td>\n",
              "      <td>pricey</td>\n",
              "      <td>tea</td>\n",
              "      <td>flavor</td>\n",
              "      <td>hot</td>\n",
              "      <td>palatable</td>\n",
              "      <td>strawberry</td>\n",
              "      <td>healthy</td>\n",
              "      <td>quick</td>\n",
              "      <td>box</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>buy</td>\n",
              "      <td>beautiful</td>\n",
              "      <td>candy</td>\n",
              "      <td>tea</td>\n",
              "      <td>tasting</td>\n",
              "      <td>delight</td>\n",
              "      <td>twizzlers</td>\n",
              "      <td>tortilla</td>\n",
              "      <td>make</td>\n",
              "      <td>hmmm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>choice</td>\n",
              "      <td>super</td>\n",
              "      <td>absolutely</td>\n",
              "      <td>work</td>\n",
              "      <td>sweet</td>\n",
              "      <td>blow</td>\n",
              "      <td>ur</td>\n",
              "      <td>amaze</td>\n",
              "      <td>hot</td>\n",
              "      <td>new</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>quite</td>\n",
              "      <td>always</td>\n",
              "      <td>em</td>\n",
              "      <td>bad</td>\n",
              "      <td>stuff</td>\n",
              "      <td>cute</td>\n",
              "      <td>earth</td>\n",
              "      <td>perfect</td>\n",
              "      <td>perfect</td>\n",
              "      <td>snack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>small</td>\n",
              "      <td>additive</td>\n",
              "      <td>healthy</td>\n",
              "      <td>buy</td>\n",
              "      <td>mint</td>\n",
              "      <td>lot</td>\n",
              "      <td>ask</td>\n",
              "      <td>rock</td>\n",
              "      <td>sauce</td>\n",
              "      <td>pack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>spicy</td>\n",
              "      <td>pop</td>\n",
              "      <td>soup</td>\n",
              "      <td>mix</td>\n",
              "      <td>world</td>\n",
              "      <td>chipslove</td>\n",
              "      <td>highfat</td>\n",
              "      <td>variety</td>\n",
              "      <td>size</td>\n",
              "      <td>perfect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>money</td>\n",
              "      <td>cup</td>\n",
              "      <td>salsa</td>\n",
              "      <td>cooky</td>\n",
              "      <td>treat</td>\n",
              "      <td>chipsyummy</td>\n",
              "      <td>organic</td>\n",
              "      <td>vinegar</td>\n",
              "      <td>wonderfully</td>\n",
              "      <td>mouth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>omg</td>\n",
              "      <td>tangy</td>\n",
              "      <td>oat</td>\n",
              "      <td>item</td>\n",
              "      <td>absolutely</td>\n",
              "      <td>chipsyum</td>\n",
              "      <td>unusual</td>\n",
              "      <td>bag</td>\n",
              "      <td>taffy</td>\n",
              "      <td>hmmmm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>instant</td>\n",
              "      <td>hard</td>\n",
              "      <td>color</td>\n",
              "      <td>treat</td>\n",
              "      <td>bar</td>\n",
              "      <td>fantastic</td>\n",
              "      <td>alternative</td>\n",
              "      <td>lover</td>\n",
              "      <td>wonderful</td>\n",
              "      <td>crave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>licorice</td>\n",
              "      <td>quick</td>\n",
              "      <td>tartlet</td>\n",
              "      <td>tasting</td>\n",
              "      <td>salsa</td>\n",
              "      <td>crisp</td>\n",
              "      <td>soup</td>\n",
              "      <td>break</td>\n",
              "      <td>filling</td>\n",
              "      <td>satisfy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic # 01  Topic # 02  Topic # 03  ... Topic # 08   Topic # 09      Topic # 10\n",
              "0        good   delicious        love  ...       chip        tasty        popchips\n",
              "1       taste  absolutely         dog  ...        pop         easy         variety\n",
              "2      flavor     healthy         cat  ...  excellent      organic          review\n",
              "3       stuff         tea       stuff  ...     kettle      crunchy            rule\n",
              "4     product        easy        food  ...   favorite      healthy           luuuv\n",
              "5      pretty     awesome     product  ...    awesome        salty  weightwatchers\n",
              "6      coffee     product       snack  ...     potato        fresh          flavor\n",
              "7        food         hot         son  ...       ever        fruit        favorite\n",
              "8     healthy      pretty     mueslix  ...       salt       beware           hella\n",
              "9      really         omg      family  ...  addictive         sooo     wonderfully\n",
              "10      price      pricey         tea  ...    healthy        quick             box\n",
              "11        buy   beautiful       candy  ...   tortilla         make            hmmm\n",
              "12     choice       super  absolutely  ...      amaze          hot             new\n",
              "13      quite      always          em  ...    perfect      perfect           snack\n",
              "14      small    additive     healthy  ...       rock        sauce            pack\n",
              "15      spicy         pop        soup  ...    variety         size         perfect\n",
              "16      money         cup       salsa  ...    vinegar  wonderfully           mouth\n",
              "17        omg       tangy         oat  ...        bag        taffy           hmmmm\n",
              "18    instant        hard       color  ...      lover    wonderful           crave\n",
              "19   licorice       quick     tartlet  ...      break      filling         satisfy\n",
              "\n",
              "[20 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHugjwpIS-36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}